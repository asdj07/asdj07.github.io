<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[https流程]]></title>
    <url>%2F2019%2F03%2F11%2Fhttps%2F</url>
    <content type="text"><![CDATA[HTTPS ssl client和server双方传递数据，对数据采用对称加密算法加密（如AES，对称加密双方采用统一的密钥key） 关键在于双方如何确定这个统一的公钥所以采用非对称加密算法（如RSA ECC，密钥和私钥）对AES的密钥进行加密传输，为了防止中间人攻击，采用第三方机构CA。 服务端首先把自己的公钥s_key_pub发给证书颁发机构，向证书颁发机构申请证书。证书颁发机构自己也有一对公钥私钥ca_key_pub ca_key。机构利用自己的私钥ca_key来加密s_key_pub，并且通过服务端网址等信息生成一个证书签名，证书签名同样经过机构的私钥加密。证书制作完成后，机构把证书发送给了服务端 client向server发送请求时，server把自己的证书发送给client，client收到证书后，对证书验证真伪。各大浏览器和操作系统已经维护了所有权威证书机构的名称和公钥。所以client只需要知道是哪个机构颁布的证书，就可以从本地找到对应的机构公钥，用机构公钥解密出证书签名并验证与请求网址是否一致（此处client验证证书签名存疑）。 一致则表明证书可靠，再解密证书，得到server的公钥s_key_pub，然后client生成自己的对称加密算法AES的密钥c_key，并用刚解密到的server的公钥s_key_pub对其进行加密然后发送给server server收到之后用自己的密钥s_key进行解密，得到了client的对称加密算法的c_key，然后server与client就通过c_key加密数据进行传输。 加密算法对称加密算法的加密与解密 密钥相同，非对称加密算法的加密密钥与解密 密钥不同，此外，还有一类 不需要密钥 的 散列算法。 对称加密: DES 3DES AES 非对称加密：RSA DSA ECC RSA两个大 素数 相乘十分容易，但想要对其乘积进行 因式分解 却极其困难，因此可以将 乘积 公开作为 加密密钥 散列算法：SHA-1、MD5 参考 漫画：什么是 HTTPS 协议？]]></content>
  </entry>
  <entry>
    <title><![CDATA[ELK]]></title>
    <url>%2F2018%2F12%2F18%2FELK%2F</url>
    <content type="text"><![CDATA[elastic文档:https://www.elastic.co/guide/cn/elasticsearch/guide/cn/index.htmlhttps://www.elastic.co/guide/cn/kibana/current/getting-started.html 安装LogstashLogstash 的作用是一个数据收集器，将各种格式各种渠道的数据通过它收集解析之后格式化输出到 Elasticsearch ，最后再由Kibana 提供的比较友好的 Web 界面进行汇总、分析、搜索。ELK 内部实际就是个管道结构，数据从 Logstash 到 Elasticsearch 再到 Kibana 做可视化展示。这三个组件各自也可以单独使用，比如 Logstash 不仅可以将数据输出到Elasticsearch ，也可以到数据库、缓存等。 安装Elasticsearch 下载elastic 配置config/elasticsearch.yml 1network.host: 0.0.0.0 新建用户 123456789101112131415adduser asd #新建用户passwd asd #设置密码，输入密码visudo #root用户执行#asd ALL=(ALL) ALL #添加一行sudo sysctl -w vm.max_map_count=262144 #asd用户执行# 编辑 limits.conf 加上如下内容* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 Elastic中的数据 index，索引，相当于Mysql中的database概念，一个index就是一个数据库 查询所有索引 curl -XGET http://localhost:9200/_cat/indices 查询具体的索引 curl -XGET http://localhost:9200/index-name?pretty 删除索引 curl -XDELETE http://localhost:9200/index-name type，相当于Mysql中table的概念，一个type就是一个表，插入数据时自动创建 document，相当于Mysql中的一条数据 安装Kibana 访问 http://ip:5601 rsyslog收集日志到logstash logstash监听514端口接收rsyslog发来的udp协议的信息 123456input &#123; udp &#123; port =&gt; 514 type =&gt; "log" &#125;&#125; 配置rsyslog的配置文件/etc/rsyslog.conf 12345678910module(load="imfile" PollingInterval="5")input(type="imfile" File="/var/log/command.log" StateFile="teststatefile" Tag="bash_history" Severity="info" Facility="local7")action(type="omfwd" Target="10.0.12.70" Port="514" Protocol="udp" ) 这样可以一台中央服务器部署logstash接收各服务器通过rsyslog传来的日志信息，进行统一处理，logstash服务器作为rsyslog的服务端。也可以在每台服务器上安装logstash收集信息，但这样每台服务器都安装比较麻烦，通过系统自带的rsyslog较为方便。 参考 https://qii404.me/2018/11/22/elastic-search.htmlhttp://www.ruanyifeng.com/blog/2017/08/elasticsearch.html 收集bash historyhttp://blog.51cto.com/dl528888/1703059 rsysloghttps://www.rsyslog.com/https://linux.cn/article-4835-1.html 安装脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899########### 安装java环境，1.8及以上 ###################### 安装Elasticsearch ###########cd /usr/localELASTIC_VERSION=6.5.0wget https://mirrors.d.com/software/elasticsearch/elasticsearch-$ELASTIC_VERSION.tar.gztar zxf ./elasticsearch-$ELASTIC_VERSION.tar.gzrm -rf ./elasticsearch-$ELASTIC_VERSION.tar.gzln -s /usr/local/elasticsearch-$ELASTIC_VERSION /usr/local/elastic### 允许外网访问sed -i 's/#network.host: 192.168.0.1/network.host: 0.0.0.0/' ./elastic/config/elasticsearch.ymlnetwork.host: 0.0.0.0### 新建用户，elastic不能以root用户运行adduser elastic-userpasswd elastic-user #设置密码visudo #root用户执行，添加sudo权限#elastic-user ALL=(ALL) ALL #添加一行# root用户执行，编辑 limits.conf 添加如下内容* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096# elastic-user用户执行sudo sysctl -w vm.max_map_count=262144#elastic用户 运行 -d 后台运行/usr/local/elastic/bin/elasticsearch # 访问http://ip:9200########### 安装kibana ###########cd /usr/localKIBANA_VERSION=6.5.0wget https://mirrors.d.com/software/elasticsearch/kibana-$KIBANA_VERSION-linux-x86_64.tar.gztar zxf ./kibana-$KIBANA_VERSION-linux-x86_64.tar.gzrm -rf ./kibana-$KIBANA_VERSION-linux-x86_64.tar.gzln -s /usr/local/kibana-$KIBANA_VERSION-linux-x86_64.tar.gz /usr/local/kibana### 允许外网访问sed -i 's/#server.host: "localhost"/server.host: "0.0.0.0"/' ./config/kibana.yml### 运行/usr/local/kibana/bin/kibana# 访问 http://ip:5601 ########### 安装logstash ###########cd /usr/localLOGSTASH_VERSION=6.5.1wget https://mirrors.d.com/software/elasticsearch/logstash-$LOGSTASH_VERSION.tar.gztar zxf ./logstash-$LOGSTASH_VERSION.tar.gzrm -rf ./logstash-$LOGSTASH_VERSION.tar.gzln -s /usr/local/logstash-$LOGSTASH_VERSION /usr/local/logstash# 运行，配置文件 /usr/local/logstash/config/xxx.confcd /usr/local/logstash &amp;&amp; ./bin/logstash -f ./config/xxx.conf########### 配置rsyslog客户端 ###########vim /etc/rsyslog.conf #添加如下内容module(load="imfile" PollingInterval="5")input(type="imfile" File="/var/log/my_bash_history.log" StateFile="teststatefile" Tag="bash_history" Severity="info" Facility="local7" ruleset="remote-server")ruleset(name="remote-server")&#123; action(type="omfwd" Target="10.0.30.210" Port="514" Protocol="udp" )&#125;########### 配置客户端收集bash_history命令 ###########vim /etc/bashrc #添加如下内容HISTDIR='/var/log/bash_history.log'if [ ! -f $HISTDIR ];thentouch $HISTDIRchmod 666 $HISTDIRfiexport HISTTIMEFORMAT="&#123;\"TIME\":\"%F %T\",\"HOSTNAME\":\"$HOSTNAME\",\"LI\":\"$(who -u am i 2&gt;/dev/null| awk '&#123;print $NF&#125;'|sed -e 's/[()]//g')\",\"LU\":\"$(who am i|awk '&#123;print $1&#125;')\",\"NU\":\"$&#123;USER&#125;\",\"CMD\":\""export PROMPT_COMMAND='history 1|tail -1|sed "s/^[ ]\+[0-9]\+ //"|sed "s/$/\"&#125;/"&gt;&gt; /var/log/bash_history.log'source /etc/bashrc #执行service rsyslog restart #重启rsyslog服务]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux命令]]></title>
    <url>%2F2018%2F12%2F13%2Flinux_bash%2F</url>
    <content type="text"><![CDATA[http://man.linuxde.net/ 文件 下载 wget http://xxx.com/file.zip wget -O filename.zip http://xxx.com/file.zip 下载并以不同的文件名保存 https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247484231&amp;idx=1&amp;sn=4cf217a4d692a7aba804e5d96186b15b&amp;chksm=ebd74246dca0cb5024de2f1d9f9e2ecb631e49752713c25bbe44f44856e919df5a973049c189#rd]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux用户管理]]></title>
    <url>%2F2018%2F12%2F13%2Flinux_user%2F</url>
    <content type="text"><![CDATA[推荐阅读 https://juejin.im/post/5b1e69dcf265da6e0d7a347e Linux中的账户包括： 用户账户 普通用户 超级用户 组账户 标准组 私有组 当一个用户属于多个组时，将组分为： 主组（初始组）：用户登录系统时的组 附加组：登录后可切换的其他组 账户的实质上就是用户在系统上的标识，这些标识是用文件保存起来的。 /etc/passwd name:password:uid:gid:description:home:shell /etc/shadow /etc/group /etc/gshdow su 和 sudo的区别 su方式切换是须要输入目标用户的password。而sudo仅仅须要输入自己的passwor。通过visudo修改用户执行sudo命令的权限. 常用命令 新建用户 adduser &lt;username&gt;设置用户秘密 passwd &lt;username&gt; 参考https://www.cnblogs.com/slgkaifa/p/6852884.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[git命令]]></title>
    <url>%2F2018%2F12%2F13%2Fgit%2F</url>
    <content type="text"><![CDATA[分支 查看分支 git branch 查看远程分支 git branch -r 查看所有分支 git branch -a 创建分支 git branch &lt;name&gt; 切换分支 git checkout &lt;name&gt; 创建+切换分支 git checkout -b &lt;name&gt; 合并某分支到当前分支 git merge &lt;name&gt; 删除分支 git branch -d &lt;name&gt; 将本地新建的分支提交到远程仓库 git push origin new-branch 初始化并提交到远程仓库 本地工程git初始化 git init 添加 git add . 提交到本地仓库 git commit -m &quot;first commit&quot; 设置远程仓库 git remote add origin git@github.com:asdj07/xxx.git 推送到远程仓库 git push -u origin master 从远程仓库更新到本地 git fetch 默认取回所有分支的更新 git fetch origin]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC]]></title>
    <url>%2F2018%2F12%2F12%2Fspring_ioc%2F</url>
    <content type="text"><![CDATA[BeanFactory getBean(name) BeanFactory BeanFactory 1234567891011121314151617181920public interface BeanFactory &#123; //这里是对FactoryBean的转义定义，因为如果使用bean的名字检索FactoryBean得到的对象是工厂生成的对象 String FACTORY_BEAN_PREFIX = "&amp;"; //这里根据bean的名字，在IOC容器中得到bean实例，这个IOC容器就是一个大的抽象工厂。 Object getBean(String name) throws BeansException; //这里根据bean的名字和Class类型来得到bean实例，和上面的方法不同在于它会抛出异常：如果根据名字取得的bean实例的Class类型和需要的不同的话。 &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType); &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException; Object getBean(String name, Object... args) throws BeansException; //这里提供对bean的检索，看看是否在IOC容器有这个名字的bean boolean containsBean(String name); //这里根据bean名字得到bean实例，并同时判断这个bean是不是单件 boolean isSingleton(String name) throws NoSuchBeanDefinitionException; //这里根据bean名字得到bean实例，并同时判断这个bean是不是原型 boolean isPrototype(String name) throws NoSuchBeanDefinitionException; //这里对得到bean实例的Class类型 Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException; //这里得到bean的别名，如果根据别名检索，那么其原名也会被检索出来 String[] getAliases(String name);&#125; HierarchicalBeanFactory，是为了实现bean工厂的层级关系提供支持，其中声明两个方法 1234//得到父工厂BeanFactory getParentBeanFactory();//在本地工厂中有没有给定名称的bean，不包括继承的工厂boolean containsLocalBean(String name); getBean()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193public Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125;protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; // beanName转换 1、移除&amp;开头的字符 2、处理alis别名 final String beanName = transformedBeanName(name); Object bean; //从bean的实例缓存中获取，singletonObjects缓存，map结构 Map&lt;beanName, beanInstance&gt; Object sharedInstance = getSingleton(beanName); // sharedInstance = null，缓存里还没有对应的实例，表明这个实例还没创建。 // BeanFactory 并不会在一开始就将所有的单例 bean 实例化好，而是在调用 getBean 获取时再实例化，懒加载 // ApplicatioContext会在spring启动时先将所有的bean都加载好 // getBean 方法有很多重载，比如 getBean(String name, Object... args) // BeanFactory 会根据这些参数 args 去匹配合适的构造方法构造 bean 实例。 if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; //如果 sharedInstance 是普通的单例 bean，下面的方法会直接返回 //如果sharedInstance 是 FactoryBean 类型的，则需调用 getObject 工厂方法获取真正的bean 实例 //如果用户想获取 FactoryBean 本身，这里也不会做特别的处理，直接返回 //FactoryBean 的实现类本身也是一种 bean。 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; /* * 如果上面的条件不满足，则表明 sharedInstance 可能为空，此时 beanName 对应的 bean * 实例可能还未创建。这里还存在另一种可能，如果当前容器有父容器，beanName 对应的 bean 实例 * 可能是在父容器中被创建了，所以在创建实例前，需要先去父容器里检查一下。 */ else &#123; //如果上面的条件不满足，则表明 sharedInstance 可能为空，此时 beanName 对应的 bean还未创建 //还存在另一种可能，如果当前容器有父容器，beanName 对应的 bean 实例可能在父容器中创建了 //所以需要检查一下父容器 // BeanFactory 不缓存 Prototype 类型的 bean，无法处理该类型 bean 的循环依赖问题 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // 如果 sharedInstance = null，则到父容器中查找 bean 实例 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // 获取 name 对应的 beanName，如果 name 是以 &amp; 字符开头，则返回 &amp; + beanName String nameToLookup = originalBeanName(name); // 根据 args 是否为空，以决定调用父容器哪个方法获取 bean if (args != null) &#123; return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; // 合并父 BeanDefinition 与子 BeanDefinition final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 检查是否有 dependsOn 依赖，如果有则先初始化所依赖的 bean String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; //检测是否存在 depends-on 循环依赖 //depends-on 循环，Spring 会直接抛出异常 if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; // 注册依赖记录 registerDependentBean(dep, beanName); try &#123; // 加载 depends-on 依赖 getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "'" + beanName + "' depends on missing bean '" + dep + "'", ex); &#125; &#125; &#125; // 创建 bean 实例 if (mbd.isSingleton()) &#123; /* * 这里并没有直接调用 createBean 方法创建 bean 实例，而是通过 * getSingleton(String, ObjectFactory) 方法获取 bean 实例。 * getSingleton(String, ObjectFactory) 方法会在内部调用 * ObjectFactory 的 getObject() 方法创建 bean，并会在创建完成后， * 将 bean 放入缓存中。关于 getSingleton 方法的分析，本文先不展开，我会在 * 后面的文章中进行分析 */ sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; // 创建 bean 实例 return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125; &#125;); // 如果 bean 是 FactoryBean 类型，则调用工厂方法获取真正的 bean 实例。否则直接返回 bean 实例 bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // 创建 prototype 类型的 bean 实例 else if (mbd.isPrototype()) &#123; Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; // 创建其他类型的 bean 实例 else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider " + "defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // 如果需要进行类型转换，则在此处进行转换。类型转换这一块我没细看，就不多说了。 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; // 返回 bean return (T) bean;&#125; beanName转换 处理以字符 &amp; 开头的 name，处理别名。123456protected String transformedBeanName(String name) &#123; // 这里调用了两个方法： // BeanFactoryUtils.transformedBeanName(name) 处理&amp;字符 //canonicalName 转换别名 return canonicalName(BeanFactoryUtils.transformedBeanName(name));&#125; 从缓存中获取bean实例。 对于单例bean，Spring容器只会实例化一次。后续再次获取时，只需直接从缓存里获取即可，无需且不能再次实例化。 从缓存中取bean实例的方法是getSingleton(String)。123456789101112131415161718192021222324252627282930public Object getSingleton(String beanName) &#123; return getSingleton(beanName, true);&#125;// allowEarlyReference表示是否允许其他 bean 引用正在创建中的 bean，用于处理循环引用的问题。protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 从 singletonObjects 获取实例，singletonObjects 中缓存的实例都是完全实例化好的 bean，可以直接使用 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 从 earlySingletonObjects 中获取提前曝光的 bean，用于处理循环引用 singletonObject = this.earlySingletonObjects.get(beanName); // 如果如果 singletonObject = null，且允许提前曝光 bean 实例，则从相应的 ObjectFactory 获取一个原始的（raw）bean（尚未填充属性） if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 获取相应的工厂类，获取对应beanName的工厂类 ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; // 提前曝光 bean 实例，用于解决循环依赖 //此处为实际创建bean实例 singletonObject = singletonFactory.getObject(); // 放入上级缓存，如果还有其他 bean 依赖当前 bean，其他 bean 可以直接从 earlySingletonObjects 取结果 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125; 其中涉及了三个缓存 合并父 BeanDefinition 与 子 BeanDefinition Spring 支持配置继承，在标签中可以使用parent属性配置父类 bean。这样子类 bean 可以继承父类 bean 的配置信息，同时也可覆盖父类中的配置。比如下面的配置： 1234567&lt;bean id=&quot;hello&quot; class=&quot;xyz.coolblog.innerbean.Hello&quot;&gt; &lt;property name=&quot;content&quot; value=&quot;hello&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;hello-child&quot; parent=&quot;hello&quot;&gt; &lt;property name=&quot;content&quot; value=&quot;I`m hello-child&quot;/&gt;&lt;/bean&gt; 从 FactoryBean 中获取 bean 实例 单例类型，将FactoryBean生成的bean放入缓存 非单例，每次创建新的bean 参考 Spring IOC 容器源码分析 - 循环依赖的解决办法Spring IOC 容器源码分析 - 获取单例 beanSpring IOC 容器源码分析系列文章]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring redis cache]]></title>
    <url>%2F2018%2F12%2F12%2Fspring_redis_cache_table%2F</url>
    <content type="text"><![CDATA[Spring 3.1 引入了激动人心的基于注释（annotation）的缓存（cache）技术，它本质上不是一个具体的缓存实现方案（例如 EHCache 或者 OSCache），而是一个对缓存使用的抽象，通过注解对方法的传参和返回值进行缓存，对任意方法进行缓存，缓存方法不能与被调用的方法在同一个类中。默认情况下会使用基于内存map一种缓存方案ConcurrenMapCacheManager。也可以通过配置使用Redis等。 Mybatis缓存，Mybatis自己有一级缓存、二级缓存，可以通过实现org.apache.ibatis.cache.Cache接口，实现Mybatis的二级缓存。此种方法只能对sql查询进行缓存，而Spring cache可以对任意方法进行缓存。Mybatis默认就支持一级缓存,如果Mybatis与Spring整合了，Spring会自动关闭sqlSession的。所以一级缓存会失效。 1、Redis安装 配置redis.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 设置密码authrequirepass#允许外网访问#bind protected-mode no# 后台运行daemonize yes pdifile：把pid文件放在/var/run/redis.pid，可以配置到其他地址 bind：指定redis只接收来自该IP的请求，如果不设置，那么将处理所有请求，在生产环节中最好设置该项 port：监听端口，默认为6379 timeout：设置客户端连接时的超时时间，单位为秒 loglevel：等级分为4级，debug，revbose，notice和warning。生产环境下一般开启notice logfile：配置log文件地址，默认使用标准输出，即打印在命令行终端的端口上 database：设置数据库的个数，默认使用的数据库是0 save：设置redis进行数据库镜像的频率 rdbcompression：在进行镜像备份时，是否进行压缩 dbfilename：镜像备份文件的文件名 dir：数据库镜像备份的文件放置的路径 slaveof：设置该数据库为其他数据库的从数据库 masterauth：当主数据库连接需要密码验证时，在这里设定 requirepass：设置客户端连接后进行任何其他指定前需要使用的密码 maxclients：限制同时连接的客户端数量 maxmemory：设置redis能够使用的最大内存 appendonly：开启appendonly模式后，redis会把每一次所接收到的写操作都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态 appendfsync：设置appendonly.aof文件进行同步的频率 vm_enabled：是否开启虚拟内存支持 vm_swap_file：设置虚拟内存的交换文件的路径 vm_max_momery：设置开启虚拟内存后，redis将使用的最大物理内存的大小，默认为0 vm_page_size：设置虚拟内存页的大小 vm_pages：设置交换文件的总的page数量 vm_max_thrrads：设置vm IO同时使用的线程数量 2、Redis数据类型 String Hash List Set 3、Spring boot集成Redis pom.xml 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; application.yaml 123456789spring: redis: host: port: 6379 password: jedis: pool: max-active: 8 # 最大连接数 max-idle: 10 # 最大空闲连接 RedisUtil 12345678910111213141516171819202122232425262728293031@Servicepublic class RedisUtil &#123; private RedisTemplate&lt;Object, Object&gt; redisTemplate; @Autowired(required = false) public void setRedisTemplate(RedisTemplate redisTemplate) &#123; // 重定义redis序列化器，去除key值首部乱码 RedisSerializer stringSerializer = new StringRedisSerializer(); redisTemplate.setKeySerializer(stringSerializer); redisTemplate.setValueSerializer(stringSerializer); redisTemplate.setHashKeySerializer(stringSerializer); redisTemplate.setHashValueSerializer(stringSerializer); this.redisTemplate = redisTemplate; &#125; public void put(String key, String value, long expire) &#123; redisTemplate.opsForValue().set(key, value, expire, TimeUnit.SECONDS); &#125; public void put(String key, String value) &#123; redisTemplate.opsForValue().set(key, value); &#125; public Object get(String key) &#123; return redisTemplate.opsForValue().get(key); &#125; public void hput(String h, String hk , String hv) &#123; redisTemplate.opsForHash().put(h, hk, hv); &#125;&#125; 4、Spring boot cache spring boot中开启缓存，默认情况下会使用基于内存map一种缓存方案ConcurrenMapCacheManager。也可以通过配置使用Redis等。缓存方法不能与被调用的方法在同一个类中。 123@Cacheable@CachePut @CacheEvict 开启缓存 1234567891011121314// pom引入相应包&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt;@SpringBootApplication @EnableCaching //启用缓存public class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class, args); &#125;&#125; 4、Spring boot redis cache RedisCacheConfig 12345678910111213141516171819202122232425262728@Configurationpublic class RedisCacheConfig &#123; @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;Object, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); return redisTemplate; &#125; @Bean public RedisCacheManager cacheManager(RedisTemplate redisTemplate) &#123; //获得redis缓存管理类 RedisCacheManager redisCacheManager = new RedisCacheManager(redisTemplate); // 开启使用缓存名称做为key前缀(这样所有同名缓存会整理在一起比较容易查找) redisCacheManager.setUsePrefix(true); //这里可以设置一个默认的过期时间 单位是秒 redisCacheManager.setDefaultExpiration(60); // 设置缓存的过期时间 单位是秒 //Map&lt;String, Long&gt; expires = new HashMap&lt;&gt;(); //expires.put("pub.imlichao.CacheTest.cacheFunction", 100L); //redisCacheManager.setExpires(expires); return redisCacheManager; &#125;&#125; UserService 123456789101112131415161718192021222324252627282930@Slf4j@Servicepublic class UserService &#123; @Autowired private UserMapper userMapper; @Cacheable(value = "User", key="#name") public List&lt;User&gt; getUserByName(String name) &#123; log.info("method == getUserByName"); List&lt;User&gt; user = userMapper.findByName(name); return user; &#125;// @CachePut(value = "User", key="#name") //更新缓存// public List&lt;User&gt; updateUserByName(String name, User user) &#123;// log.info("method == updateUserByName");// userMapper.update(user);// List&lt;User&gt; userList = new ArrayList&lt;User&gt;();;// userList.add(user);// return userList;// &#125; @CacheEvict(value = "User", key="#name") //删除缓存 public void updateUserByName(String name, User user) &#123; log.info("method == updateUserByName"); userMapper.update(user); &#125;&#125; 5、mybatis cache Mybatis一级缓存 Mybatis的一级缓存是指Session缓存。一级缓存的作用域默认是一个SqlSession。Mybatis默认开启一级缓存。 也就是在同一个SqlSession中，执行相同的查询SQL，第一次会去数据库进行查询，并写到缓存中； 第二次以后是直接去缓存中取。 当执行SQL查询中间发生了增删改的操作，MyBatis会把SqlSession的缓存清空。 如果Mybatis与Spring整合了，Spring会自动关闭sqlSession的。所以一级缓存会失效的。 SqlSession -&gt; Executor -&gt; cache Mybatis二级缓存 mapper 参考 spring cache https://my.oschina.net/u/3452433/blog/1831026 https://juejin.im/entry/59a4d74b518825244d205485 mybatis cachehttps://blog.csdn.net/luanlouis/article/details/41280959 https://blog.csdn.net/luanlouis/article/details/41390801 https://zhuanlan.zhihu.com/p/27726873 https://www.jianshu.com/p/c553169c5921]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java jvm]]></title>
    <url>%2F2018%2F12%2F12%2Fjava_jvm%2F</url>
    <content type="text"><![CDATA[Java运行时数据区程序计数器（PC） 线程私有，是一块很小的内存区域，存储了下一条需要执行的（JVM汇编）字节码的指令地址 每个线程都有自己的PC，记录了当前线程要执行的指令。 虚拟机栈（VM Stack） 线程私有，此栈中的元素叫做栈帧，线程在调用java方法时会为每一个元素创建一个栈帧，来存储局部变量表，操作表，动态链接，方法出口等信息， 每个方法被调用和完成的过程，都对应一个栈帧从虚拟机栈上的入栈和出栈的过程。虚拟机栈的生命周期和虚拟机相同。 后入先出栈，线程调用对象方法时，JVM会创建一个栈帧放到虚拟机栈中，用来表示某个方法的调用，调用过程就是方法的入栈和出栈过程。 栈帧中包含的内容： 局部变量表 操作数栈 动态链接 方法出口 本地方法栈（Native Method Stack） 线程私有，功能和虚拟机栈相似 存储线程调用本地方法时，本地放法的局部变量表，操作栈等。 堆 （Heap） Heap区被所有的线程共享，在虚拟机启动时创建 存放对象实例，Heap区是垃圾回收管理的主要区域 方法区（Method area） 被所有线程共享，用于存储已经被虚拟机加载的类信息，常亮，静态变量，即时编译器编译出来的代码等数据。 运行时常量池 类型信息 字段信息 方法信息 类信息 指向类加载和class实例的引用 方法表 JVM监控 jps 功能类似ps，列出正在运行的虚拟机进程 jstat，显示本地或远程中的类装载，内存，垃圾收集，JIT编译等运行数据。 jinfo jstack JConsole 可视化工具 Java VisualVM JVM参数 -Xms 初始堆大小 -Xmx 最大堆大小 -Xmn 设置年轻代大小 -XX:NewSize 设置新生代最小空间大小 -XX:MaxNewSize 设置新生代最大空间大小 -Xss 设置每个线程的堆栈大小 推荐阅读 https://github.com/Snailclimb/JavaGuide/blob/master/Java%E7%9B%B8%E5%85%B3/%E5%8F%AF%E8%83%BD%E6%98%AF%E6%8A%8AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AE%B2%E7%9A%84%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0.md Java运行时数据区:https://blog.csdn.net/luanlouis/article/details/40043991Java类加载:https://blog.csdn.net/luanlouis/article/details/50529868]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux与windows之间网络共享]]></title>
    <url>%2F2018%2F12%2F12%2Flinux_win_file%2F</url>
    <content type="text"><![CDATA[Samba 安装Samba`yum install samba` 配置 /etc/samba/smb.conf 参考https://segmentfault.com/a/1190000005821820]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LRU cache]]></title>
    <url>%2F2018%2F12%2F07%2Flru%2F</url>
    <content type="text"><![CDATA[数据结构 采用 HashMap 和 双向链表的数据结构 双向链表中的Node保存了缓存的key和value HashMap&lt;key, Node&gt;，即value为双向链表中的节点 每访问一个元素将双向链表中的该元素先删除，再添加到头结点，即将最新访问的节点移到头 当缓存满，删除链表尾的节点，同时删除map中的key，再将新元素添加到链表头，添加到map 用双向链表是为了记录尾节点，当缓存满时删除尾节点 第一开始想法是用单向链表，再额外记录一下头尾节点，但这样是不行的，单向链表可以记录头结点，没有办法记录尾节点，当一个尾节点被删除后，只能从头遍历到尾才能继续记录尾节点。 如何实现一个高并发下的线程安全的 LRU缓存 ？ 参考：LRU原理和Redis实现]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[小柯基]]></title>
    <url>%2F2018%2F11%2F17%2F20181117%2F</url>
    <content type="text"><![CDATA[天气有点冷了。 前些天 11.6 抱了一只柯基，很可爱，以前刚毕业的时候就想养一只狗。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>me</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[星期六上午]]></title>
    <url>%2F2018%2F11%2F03%2F20181103%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer-VxwCusLj"), narrow: false, autoplay: true, showlrc: false, music: { title: "理想", author: "赵雷", url: "http://image.asdj.me/image/blog/video/赵雷_-_理想.mp3", pic: "", lrc: "" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 今天重新建了这个博客，希望以后能坚持记录一些东西。 最近发生了好多事情。情绪太复杂。 明天和意外不知道哪一个先来。 又何必去想那么多。 就这样吧。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>me</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础知识总结]]></title>
    <url>%2F2018%2F11%2F03%2Flgorithm%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础知识总结]]></title>
    <url>%2F2018%2F11%2F03%2Flearning%2F</url>
    <content type="text"><![CDATA[基础知识 Java1、什么是多态？哪里体现了多态的概念？ SOA，微服务2、HashMap、TreeMap、HashTable、ConcurrentHashMap、ArrayList、LinkList HashMap实现原理，链表的数组，JDK8优化了数组为红黑树，hash函数映射到相应的数组下 HashMap的长度和扩容，默认初始数组长度是16，每次扩容c长度必须是2的幂，哈希函数采用位运算 index = HashCode（Key） &amp; （Length - 1） ，所以 length - 1 的二进制必须全为1，这样 &amp; 结果才能完全的分布在 0 ~ length - 1 HashMap扩容，当 HashMap.Size &gt;= Capacity * LoadFactor时，其中Capacityhashmap当前数组长度，LoadFactor负载因子默认是0.75f， 执行resize()方法，包含两步: 创建一个新的Entry空数组，长度是原数组的2倍。 ReHash，遍历原Entry数组，把所有的Entry重新Hash到新数组。多线程时rehash时有可能会使链表出现环，所以HashMap是线程不安全的。 HashTable和ConcurrentHashMap，ConcurrentHashMap相当于一个二级哈希表，在一个总的哈希表下面，有若干个子哈希表segment，对每一个segment加锁，只有在同一个segment同时进行写操作时才会发生阻塞。ConcurrentHashMap的size方法统计，遍历segment统计数量前后记录segment的修改次数，若一致则表明统计过程中没有新元素插入，不一致则重新统计。HashTable是全加锁，性能较差。 LinkedHashMap，有序的HashMap 3、java中四种修饰符的限制范围 public 可以被所以类访问 private 只能被自己访问或修饰 protected 自身，子类或同一个包中的类 default 同一包中的类可以访问 4、Object类中的方法5、动态代理的两种方式，以及区别。 JDK动态代理,它的实现原理，就是通过让target类和代理类实现同一接口，代理类持有target对象，来达到方法拦截的作用，这样通过接口的方式有两个弊端，一个是必须保证target类有接口，第二个是如果想要对target类的方法进行代理拦截，那么就要保证这些方法都要在接口中声明，实现上略微有点限制。 cglib动态代理，它的底层使用ASM在内存中动态的生成被代理类的子类，使用CGLIB即使代理类没有实现任何接口也可以实现动态代理功能。cglib封装了asm，可以在运行期动态生成新的class。cglib用于AOP，jdk中的proxy必须基于接口，cglib却没有这个限制。 如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP；如果目标对象实现了接口，可以强制使用CGLIB实现AOP；如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换。 6、接口和抽象类的区别 抽象类中可以写非抽象的方法，从而避免在子类中重复书写他们，这样可以提高代码的复用性，这是抽象类的优势；接口中只能有抽象的方法。 一个类只能继承一个直接父类，这个父类可以是具体的类也可是抽象类；但是一个类可以实现多个接口。 7、Java序列化 在Java中，只要一个类实现了java.io.Serializable接口，那么它就可以被序列化。 通过ObjectOutputStream和 ObjectInputStream对对象进行序列化及反序列化。 序列化并不保存静态变量。 transient 关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以阻止该变量被序列化到文件中，在被反序列化后，transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。 Externalizable继承了Serializable，该接口中定义了两个抽象方法：writeExternal()与readExternal()。 8、传值和传引用 java中方法参数传递方式是按值传递。 如果参数是基本类型，传递的是基本类型的字面量值的拷贝。 如果参数是引用类型，传递的是该参量所引用的对象在堆中地址值的拷贝。 9、事务10、异常11、一个ArrayList在循环过程中删除，会不会出问题，为什么12 设计模式，单例模式（懒汉恶汉，枚举） 多线程Java实现多线程有哪几种方式。 继承Thread类 实现Runnable接口 一般采用通过实现Runable接口的方式，避免Java中类的单继承限制 ABC三个线程如何保证顺序执行sleep和wait的区别 sleep是Thread类的方法,wait是Object类中定义的方法 Thread.sleep不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep不会让线程释放锁。和锁相关的方法都定义在Object类中，因此调用Thread.sleep是不会影响锁的相关行为。 wait必须在synchronized块中。wait执行时会释放对象锁，通过使用notify或者notifyAll来唤醒 notify和notifyall的区别 锁池，等待池 notifyAll调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，而notify只会唤醒一个线程 notify唤醒一个等待的线程；notifyAll唤醒所有等待的线程 volitile关键字的作用，原理 保持内存可见性，所有线程都能看到共享内存的最新状态 数据缓存一致性：缓存一致性协议，总线加LOCK锁 防止指令重排序 synchronized关键字的用法，优缺点 是一种互斥锁，一次只能允许一个线程进入被锁住的代码块 乐观锁和悲观锁，CAS 悲观锁 总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 悲观锁适用于多写场景。 * 乐观锁， 总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。乐观锁适用于多读场景。 版本号实现方式，在数据更新过程前后读取版本号version字段，前后version值相等时才进行更新，否则重试更新操作直到成功。 CAS算法实现方式，compare and swap，非阻塞同步. ABA问题，JDK 1.5 以后，其中的 compareAndSet方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 可重入锁的用处及实现原理，写时复制的过程，读写锁，分段锁（ConcurrentHashMap中的segment） Callable和Future的了解。 线程池的参数有哪些，在线程池创建一个线程的过程。 Lock接口有哪些实现类，使用场景是什么。 线程的状态都有哪些。 ThreadLocal的了解，实现原理。 JVMJava内存模型垃圾回收算法，分代类加载，双亲委托机制JVM方法栈的工作过程，方法栈和本地方法栈有什么区别。 JVM的栈中引用如何和堆中的对象产生关联。 GC的常见算法，CMS以及G1的垃圾回收过程，CMS的各个阶段哪两个是Stop the world的，CMS会不会产生碎片，G1的优势。 标记清除和标记整理算法的理解以及优缺点。 eden survivor区的比例，为什么是这个比例，eden survivor的工作过程。 JVM如何判断一个对象是否该被GC，可以视为root的都有哪几种类型。 强软弱虚引用的区别以及GC对他们执行怎样的操作。 Java是否可以GC直接内存。 常用的JVM调优参数。 dump文件的分析。 Java有没有主动触发GC的方式（没有）。 数据结构1、红黑树，二叉树，B树2、动态规划3、栈和堆的区别4、链表，判断环，5、排序算法，快排，堆排序，插入排序 6、一致性Hash算法，应用 Spring1、IOC2、AOP 数据库常见的数据库优化手段 数据库连接池 1、SQL慢查询的优化2、left join 和 inner join3、索引4、mybatis配置了xml过后是如何完成数据库操作的5、redis 计算机网络1、Https2、TCP 容器1、tomcat 2、nginx 3、docker 4、k8s]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>me</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 多线程]]></title>
    <url>%2F2018%2F08%2F12%2Fjava_thread%2F</url>
    <content type="text"><![CDATA[创建多线程有两种方法 继承Thread，重写run方法 1234567891011121314151617public class MyThread extends Thread &#123; @Override public void run() &#123; for (int x = 0; x &lt; 200; x++) &#123; System.out.println(x); &#125; &#125;&#125;public class MyThreadDemo &#123; public static void main(String[] args) &#123; MyThread my1 = new MyThread(); MyThread my2 = new MyThread(); my1.start(); my2.start(); &#125;&#125; 实现Runnable接口，重写run方法 123456789101112131415161718public class MyRunnable implements Runnable &#123; @Override public void run() &#123; for (int x = 0; x &lt; 100; x++) &#123; System.out.println(x); &#125; &#125;&#125;public class MyRunnableDemo &#123; public static void main(String[] args) &#123; MyRunnable my = new MyRunnable(); Thread t1 = new Thread(my); Thread t2 = new Thread(my); t1.start(); t2.start(); &#125;&#125; run()和start()方法区别: run()，仅仅是封装被线程执行的代码，直接调用是普通方法 start()，首先启动了线程，然后再由jvm去调用该线程的run()方法。 一般使用多线程通过实现Runnable接口实现 可以避免java中的单继承的限制 将并发运行任务和运行机制解耦 参考https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247484190&amp;idx=1&amp;sn=ab7301e393aa7762be9ef80d30c5fb7a&amp;chksm=ebd7421fdca0cb09f4a880064a8610416df414ea25284e6d5142ea659e4e7e669632cfed4050#rd]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes]]></title>
    <url>%2F2018%2F07%2F18%2FKubernetes%2F</url>
    <content type="text"><![CDATA[Kubernetes 文档： http://docs.kubernetes.org.cn/ kubectl命令 123456789101112131415161718# namespacekubectl create namespace my-namespacekubectl delete namespaces new-namespacekubectl get namespaces# deploymentkubectl create -f ./xx.yamlkubectl get deployments -n namespacekubectl get po -n namespacekubectl exec -ti xx-c48dfb898-7tzrc -n namespace -- /bin/sh# servicekubectl expose deployment/my-nginx -n namespace# nfs 目录挂载showmount -e nfs.d.commount -t nfs nfs.d.com://srv/nfs/xx ./nfs-mount/xx xxx.yaml，创建pod Pod是Kubernetes创建或部署的最小/最简单的基本单位，一个Pod代表集群上正在运行的一个进程。 一个Pod封装一个应用容器（也可以有多个容器），存储资源、一个独立的网络IP以及管理控制容器运行方式的策略选项。Pod代表部署的一个单位：Kubernetes中单个应用的实例，它可能由单个容器或多个容器共享组成的资源。 Docker是Kubernetes Pod中最常见的runtime ，Pods也支持其他容器runtimes。1234567891011121314151617181920212223242526272829---apiVersion: apps/v1kind: Deploymentmetadata: name: testspec: selector: matchLabels: app: test replicas: 1 template: metadata: labels: app: test spec: containers: - name: test image: nodejs:8.11.2-LTS imagePullPolicy: IfNotPresent ports: - containerPort: 80 volumeMounts: - name: nfs mountPath: /srv/volume/test volumes: - name: nfs nfs: server: nfs.com path: /srv/nfs/test ConfigMap configmap 用来保存一个或多个key/value信息123456789---kind: ConfigMapapiVersion: v1metadata: name: ipbank-manager-fe namespace: cetiti-trdata: site.conf: | .nginx.conf Service Kubernetes Service 定义了这样一种抽象：一个 Pod 的逻辑分组，一种可以访问它们的策略 —— 通常称为微服务。 这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector实现的。 对 Kubernetes 集群中的应用，Kubernetes 提供了简单的 Endpoints API，只要 Service 中的一组 Pod 发生变更，应用程序就会被更新。 对非 Kubernetes 集群中的应用，Kubernetes 提供了基于 VIP 的网桥的方式访问 Service，再由 Service 重定向到 backend Pod。1234567891011121314---kind: ServiceapiVersion: v1metadata: name: name namespace: cetiti-trspec: selector: app: name-dev #定位到名为name-dev的pod上 type: ClusterIP ports: - protocol: TCP port: 80 targetPort: 80 kubernetes ingress 参考 https://www.kubernetes.org.cn/1885.html service和pod仅可在集群内部网络中通过IP地址访问。所有到达边界路由器的流量或被丢弃或被转发到其他地方。Ingress是授权入站连接到达集群服务的规则集合。 可以给Ingress配置提供外部可访问的URL、负载均衡、SSL、基于名称的虚拟主机等。用户通过POST Ingress资源到API server的方式来请求ingress。123456789101112131415161718192021# ingress.yamlapiVersion: extensions/v1beta1kind: Ingressmetadata: name: testspec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80# kubectl create -f ./ingress.yaml -n namespace# kubectl get ing -n namespace]]></content>
      <categories>
        <category>容器</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java jvm]]></title>
    <url>%2F2018%2F06%2F19%2Fnginx%2F</url>
    <content type="text"><![CDATA[Nginx与Tomcat比较 tomcat是根据Servlet和JSP规范执行的。tomcat对静态文件、高并发文件的处理比较弱。 nginx配置文件简单；能根据域名、URL的不同将HTTP请求分发到不同的后端服务器集群；负载均衡；反向代理；内置健康检查；节省带宽。支持GZIP压缩；支持热部署。 nginx热部署的实现 Nginx涉及Master进程和Worker进程；master读取并验证配置文件nginx.conf；管理worker进程；每一个Worker进程都维护一个线程（避免线程切换），处理连接和请求。 修改配置文件nginx.conf后，重新生成新的worker进程，当然会以新的配置进行处理请求，而且新的请求必须都交给新的worker进程，至于老的worker进程，等把那些以前的请求处理完毕后，kill掉即可。 Nginx如何做到高并发 Nginx采用了Linux的epoll模型，epoll模型基于事件驱动机制，它可以监控多个事件是否准备完毕，如果OK，那么放入epoll队列中，这个过程是异步的。worker只需要从epoll队列循环处理即可。 高可用、负载均衡 Keep-Alive HAProxy LVS + Keep-Alive Linux Virtual Server F5 nginx的负载均衡策略 1、轮询（默认） 2、指定权重轮询 3、ip_hash(ip绑定)，每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 4、url_hash（第三方），按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 5、fair（第三方），按后端服务器的响应时间来分配请求，响应时间短的优先分配。 参考深入浅出搞懂NginxNginx&amp;Keepalived 实现高可用]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[postgres备份]]></title>
    <url>%2F2018%2F01%2F23%2Fpostgres%2F</url>
    <content type="text"><![CDATA[postgres安装 centos自带postgres，通过yum list | grep postgresql查看，安装最新版的postgres,安装yum源:yum install https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm 安装PostgreSQL： yum install postgresql96-server postgresql96-contrib 可执行文件在 /usr/pgsql-9.6/bin/添加到环境变量， 数据和配置文件在 /var/lib/pgsql/9.6/data/ 123456export POSTGRES_HOME=/usr/pgsql-9.6export PGDATA=/var/lib/pgsql/9.6/data/export PATH=$PATH:$POSTGRES_HOME/binTZ='Asia/Shanghai'; export TZ 初始化数据库, 在数据文件目录/var/lib/pgsql/9.6/data/ 下执行 su - postgres initdb ./ 支持密码登录修改相关文件： vi /var/lib/pgsql/9.6/data/pg_hba.conf添加host all all 0.0.0.0 0.0.0.0 md5 开启远程访问，vi postgresql.conf修改 listen_addresses=&#39;*&#39; 重启postgres，su postgres -c &#39;pg_ctl restart&#39;，如果没有设置$PGDATA环境变量，执行该命令需要指定数据库目录-D /data 登录，创建用户 执行su postgres，输入psql进入postgres命令行 执行ALTER USER postgres WITH PASSWORD &#39;123456&#39; 设置postgres用户的密码 查看角色\du，创建用户并分配权限create user test_user password &#39;123456&#39; Superuser CreateDB; 删除用户drop user test_user; 退出\q postgres备份 SQL转储 文件系统级别备份 流复制 在线增量备份与任意时间点恢复 一、SQL转储SQL 转储方法的思想是创建一个由SQL命令组成的文件，当把这个文件回馈给服务器时，服务器将利用其中的SQL命令重建与转储时状态一样的数据库。pg_dump创建的备份在内部是一致的， 也就是说，转储表现了pg_dump开始运行时刻的数据库快照，且在pg_dump运行过程中发生的更新将不会被转储。pg_dump工作的时候并不阻塞其他的对数据库的操作。 （但是会阻塞那些需要排它锁的操作，比如大部分形式的ALTER TABLE） 导出数据库数据 pg_dump -U postgres -f /home/pg1.sql pg 恢复数据 psql -U postgres -f /home/pg1.sql pg pg_dump 表备份 pg_dump databasename –t tablename1 –t tablename2 &gt;filename pg_dumpall备份所有数据库及角色 pg_dumpall &gt; /home/pg_all.dmp， 恢复 psql –f /home/pg_all.dmp postgres 备份压缩(处理大型数据库) 备份 pg_dump dbname | gzip &gt; filename.gz 恢复 gunzip -c filename.gz | psql dbname 二、文件系统级别备份 连续归档基础备份pg_basebackup，被用于获得一个正在运行的PostgreSQL数据库集簇的基础备份，备份通过一个常规PostgreSQL连接制作，并且使用复制协议。获得这些备份不会影响连接到该数据库的其他客户端, 直接复制PostgreSQL用于存储数据库中数据的文件,要求主库关闭。tar -cf backup.tar /usr/local/pgsql/data 创建一个数据目录的”一致快照”，创建一个包含数据库的卷的”冻结快照”，然后从该快照复制整个数据目录（如上，不能是部分复制）到备份设备，最后释放冻结快照。即使在数据库服务器运行时，这种方式也有效。但是，以这种方式创建的备份保存的文件看起来就像数据库没有被正确关闭时的状态。因此，当你从备份数据上启动数据库服务器时，它会认为上一次的服务器实例崩溃了并尝试重放WAL日志。这不是问题，只是需要注意（当然WAL文件必须要包括在备份中）。你可以在拍摄快照之前执行一次CHECKPOINT以便节省恢复时间。 使用rsync来执行一次文件系统备份。其做法是先在数据库服务器运行时执行rsync，然后关闭数据库服务器足够长时间来做一次rsync –checksum （–checksum是必需的，因为rsync的文件修改 时间粒度只能精确到秒）。 三、流复制流复制允许一台后备服务器比使用基于文件的日志传送更能保持为最新的状态。 后备服务器连接到主服务器， 主服务器则在 WAL(write ahead log) 记录产生时即将它们以流式传送给后备服务器而不必等到 WAL文件被填充。在这种情况下主服务器上提交一个事务与该变化在后备服务器上变得可见之间存在短暂的延迟。 不过这种延迟比基于文件的日志传送方式中要小得多， 在后备服务器的能力足以跟得上负载的前提下延迟通常低于一秒。 默认情况下流复制是异步的 主库配置 创建复制用户： create user rep replication password &#39;123456&#39;; 配置pg_hba.conf： host replication rep 10.0.12.5/8 md5 配置postgresql.conf： 1234wal_level = replicahot_standby = onmax_wal_senders = 2 #流复制最大连接数wal_keep_segments = 16 #xlog段的大小 从库配置 pg_basebackup基础备份： pg_basebackup -D $PGDATA -Fp -Xs -v -P -h 10.0.12.56 -p 5432 -U rep 配置recovery.conf 1234cp /usr/pgsql-9.6/share/recovery.conf.sample $PGDATA/recovery.confvim $PGDATA/recovery.confstandby_mode = onprimary_conninfo = 'host=10.0.12.56 port=5432 user=rep password=123456' 启动postgres： pg_ctl start 测试 流复制 查看相关进程 主库查找进程ps -ef |grep postgres，其中包含 postgres: wal sender process... 从库查找进程ps -ef |grep postgres，其中包含 postgres: wal receiver process... 查看记录点 返回主库记录点、备库记录点：postgres=# select txid_current_snapshot(); 主库每增加一条写入，记录点的值就会加1 查看主备库同步状态 postgres=# select * from pg_stat_replication; 字段state显示的同步状态有：startup（连接中）、catchup（同步中）、streaming（同步）；字段sync_state显示的模式有：async（异步）、sync（同步）、potential（虽然现在是异步模式，但是有可能升级到同步模式） 此时在主库对数据的操作将会同步至备库，备库处于只读模式。参考主从切换，将备库升级为主库。 四、在线增量备份与任意时间点恢复在任何时间，PostgreSQL在数据集簇目录的pg_xlog/子目录下都保持有一个预写式日志（WAL）。这个日志存在的目的是为了保证崩溃后的安全：如果系统崩溃，可以”重放”从最后一次检查点以来的日志项来恢复数据库的一致性。该日志的存在也使得第三种备份数据库的策略变得可能：我们可以把一个文件系统级别的备份和WAL文件的备份结合起来。当需要恢复时，我们先恢复文件系统备份，然后从备份的WAL文件中重放来把系统带到一个当前状态。这种方法比之前的方法管理起来要更复杂，但是可以实现数据任意时间点恢复功能。 主库设置(基于流复制中主库的配置) 配置postgresql.conf：123#开启归档模式archive_mode = onarchive_command = &apos;ssh 10.0.12.5 test ! -f /data/postgres/pg_archive/%f &amp;&amp; scp %p 10.0.12.5:/data/postgres/pg_archive/%f&apos; 其中archive_command是归档命令，将归档文件传送至 10.0.12.5备份服务器的/data/postgres/pg_archive目录下 执行该命令前要保证 主备库服务器的免密登录, postgres用户目录在/var/lib/pgsql，切换postgres用户，执行ssh-keygen -t rsa，将生成的公钥/var/lib/pgsql/.ssh/id_rsa.pub添加到免密登录主机对应的/var/lib/pgsql/.ssh/authorized_keys文件中，注意公钥中的主机名需要在免密登录的主机上配置dns或直接改为ip地址。 重启主库pg_ctl restart 从库设置 创建存储归档文件的目录： mkdir -p /data/postgres/pg_archive，设置文件权限chown postgres:postgres /data/postgres/pg_archive 创建主库的基础备份目录 mkdir -p /data/postgres/pg_basebackup，执行pg_basebackup -D /data/postgres/pg_basebackup -Fp -Xs -v -P -h 10.0.12.56 -p 5432 -U rep将主库基础备份至该目录，然后需要修改基础备份中的postgresql.conf，关闭归档模式，注释掉archive_mode和archive_command 配置恢复文件，restore_command将归档日志复制过来，recovery_target_time是恢复到的时间点,将$PGDATA即/var/lib/pgsql/9.6/data链接到基础备份目录/data/postgres/pg_basebackup，设置权限chmod 0700 $PGDATA，启动postgres，pg_ctl start，即可恢复到指定时间点。12345cp /usr/pgsql-9.6/share/recovery.conf.sample /data/postgres/pg_basebackuprecovery.confvim recovery.confrestore_command = 'cp /data/postgres/pg_basebackup/%f %p'recovery_target_time = '2017-11-14 18:31:00' 参考资料：http://www.postgres.cn/docs/9.6/backup.html https://yq.aliyun.com/articles/59355# http://blog.csdn.net/yanggd1987/article/details/51209344 https://www.2cto.com/database/201708/670383.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>postgres</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS单点登录]]></title>
    <url>%2F2018%2F01%2F18%2Fcaslogin%2F</url>
    <content type="text"><![CDATA[单点登录SSO（Single Sign On）CAS（Central Authentication Service） cas中的关键词 TGC（ Ticket Granting Cookie），CAS域名下的cookie，CAS SERVER通过该cookie的值TGC判断用户是否登录。CAS Server 生成TGT放入自己的 Session 中，而 TGC 就是这个 Session 的唯一标识（SessionId），以 Cookie 形式放到浏览器端。 TGT（Ticket Granting Ticket），在CAS SERVER端判断用户登录的标识，TGT 封装了 Cookie 值以及此 Cookie 值对应的用户信息。当 HTTP 请求到来时，CAS 以此 Cookie 值（TGC）为 key 查询缓存中有无 TGT ，如果有的话，则相信用户已登录过。 ST（Service Ticket ），ST 是 CAS 为用户签发的访问某一 service 的票据。用户访问 service 时，service 发现用户没有 ST，则要求用户去 CAS 获取 ST。用户向 CAS 发出获取 ST 的请求，CAS 发现用户有 TGT，则签发一个 ST，返回给用户。用户拿着 ST 去访问 service，service 拿 ST 去 CAS 验证，验证通过后，允许用户访问资源。 简而言之，CAS通过多个应用系统之间共享cas-server域名下的cookie实现单点登录。 集成了cas的应用系统A进行登录认证的时候先跳转到cas的登录认证页面，登录成功之后，cas server会生成一个TGT存入自己的缓存中，同时会在cas登录认证的域名下设置cookie，即TGC，TGC中包含TGT的id。 TGT生成一个令牌ST，浏览器重定向带着ST回调系统A，应用系统A拿着ST再去向cas server请求，ST验证一次之后会失效，cas server验证ST的有效性并且将ST和应用系统A的url信息存入自己的services map中，然后返回登录的用户信息，应用系统A将y用户信息和ST存储到自己的session中。 集成了cas的应用系统B进行登录，跳转到cas的登录认证页面，A登录过程中已经在该域名下设置了cookie，即TGC，cas server验证TGC，TGC中有cas server缓存的TGT的id，TGC有效则无需登录验证，然后该TGT生成一个ST，浏览器重定向回调应用系统B，B收到ST之后再带着ST去请求cas server，cas server验证ST有效性并将ST和应用系统B的url信息存储在自己的services map中，然后返回应用系统B的用户信息。 应用系统A退出，向cas server发送退出请求，请求中含有cookie，然后cas server通过cookie找到TGT，TGT遍历所有services map，然后向service中记录的系统A，系统B发送退出请求，同时销毁TGT，系统A，系统B收到退出请求销毁对应的ST的session。 node客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354const express = require('express');const path = require('path');var http = require("http")var session = require('express-session')//var ConnectCas = require('connect-cas2')const app = express();const server_url = "http://10.70.7.222";//sso认证成功之后cas server向应用服务器回调地址，get请求返回ST，该地址需在sso上注册const callback_path = "/sso";//应用服务器获取ST后向cas server发送get请求，返回用户信息const serviceValidate_url = "http://sso.d.com/cas/p3/serviceValidate?service=http%3A%2F%2F10.70.7.222%2Fsso%2F"const logout_url = "http://sso.d.com/cas/rbac/api/logout";const port = 80;app.use(session(&#123; secret: 'portalMangeSecret', cookie: &#123; maxAge: 3600000 ,path:'/'&#125;&#125;))app.use(express.static(path.join(__dirname, 'public')))app.get("/username",function(req,res)&#123; res.writeHead(200, &#123;"Content-Type": "json; charset=UTF-8;","Access-Control-Allow-Origin":"*"&#125;); var sess = req.session; if(sess.username)&#123; res.end('&#123;"username":"' + sess.username + '"&#125;'); &#125;else&#123; res.end('&#123;"username":""&#125;'); &#125;&#125;)app.get("/logout",function(req,res)&#123; req.session.destroy(); var url = logout_url; res.redirect(302, url);&#125;)//登录成功之后sso回调,返回ticketapp.get(callback_path,function(req,res)&#123; var service_url = serviceValidate_url + "&amp;ticket="+req.query.ticket; var _res = res; var _req = req; //请求sso 返回用户信息 http.get(service_url, (res) =&gt; &#123; res.setEncoding('utf8'); let rawData = ''; res.on('data', (chunk) =&gt; rawData += chunk); res.on('end', () =&gt; &#123; try &#123; var username = rawData.match(/&lt;cas:user&gt;[a-z]*/ig)[0].substring(10); var sess = _req.session; sess.username = username; _res.redirect(302, server_url + '/index.html'); &#125; catch (e) &#123; &#125; &#125;); &#125;).on('error', (e) =&gt; &#123; &#125;);&#125;)app.listen(port, () =&gt; &#123; console.log(`App listening at port $&#123;port&#125;`)&#125;); 推荐阅读： https://juejin.im/post/5a002b536fb9a045132a1727 https://my.oschina.net/thinwonton/blog/1456722 https://my.oschina.net/thinwonton/blog/1475562]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>cas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenResty]]></title>
    <url>%2F2018%2F01%2F18%2Fopenresty%2F</url>
    <content type="text"><![CDATA[OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。 1、OpenResty安装 centos 安装 12345678910111213141516171819202122232425262728293031323334353637### yum安装yum -y install readline-devel pcre-devel openssl-develsudo yum install -y yum-utilssudo yum-config-manager --add-repo https://openresty.org/package/centos/openresty.reposudo yum install -y openresty### 源码编译# 172.24.138.8 yum install -y gcc gcc-c++ pcre-devel openssl openssl-develcd /datacurl -O http://mirrors.d.com/software/openresty/1.13.6/openresty-1.13.6.1.tar.gztar -zxvf openresty-1.13.6.1.tar.gzcd openresty-1.13.6.1#./configure # 指定libressl tls1.3 http2./configure --with-openssl=/usr/local/libressl-2.6.4 --with-openssl-opt=enable-tls1_3 --with-http_v2_modulemake sudo make install #默认安装在/usr/local/openresty目录下#将conf 和 log目录移到/data/openresty下mkdir -p /data/openrestycp -R /usr/local/openresty/nginx/conf /data/openrestyrm -rf /usr/local/openresty/nginx/confln -s /data/openresty/conf /usr/local/openresty/nginx/confmkdir -p /data/openresty/logsrm -rf /usr/local/openresty/nginx/logsln -s /data/openresty/logs /usr/local/openresty/nginx/logs#启动/usr/local/openresty/nginx/sbin/nginx#检查配置是否正确# /usr/local/openrestry/nginx/sbin/nginx -t#重新加载配置文件# /usr/local/openrestry/nginx/sbin/nginx -s reload 2、openresty配置nginx匹配规则 1234567891011121314151617181920212223= # 精确匹配~ # 正则匹配 区分大小写~* # 正则匹配 不区分大小写^~ # 普通字符匹配，location = / &#123; # 只匹配"/". [ configuration A ] &#125;location / &#123; # 匹配任何请求，因为所有请求都是以"/"开始 # 但是更长字符匹配或者正则表达式匹配会优先匹配 [ configuration B ] &#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开始的请求，并停止匹配 其它location [ configuration C ] &#125;location ~* .(gif|jpg|jpeg)$ &#123; # 匹配以 gif, jpg, or jpeg结尾的请求. # 但是所有 /images/ 目录的请求将由 [Configuration C]处理. [ configuration D ] &#125; 服务端获得客户端的真实ip123456789location /&#123; proxy_pass http://192.168.1.111:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; ## node var real_ip = req.get("X-Real-IP") || req.get("X-Forwarded-For") || req.ip; openresty 隐藏服务器名称及版本，复写http server头12345678http&#123; server_tokens off; #隐藏server版本&#125;location / &#123; #复写http server header_filter_by_lua 'ngx.header.server = "apache/2.4"';&#125; 图片服务，静态文件123456789101112131415161718server &#123; listen 80; server_name 10.0.12.75; #charset koi8-r; #access_log logs/host.access.log main; ### path /data/image/test.jpg location /image &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header Cache-Control no-store; root /data/; autoindex on; #预览 #index index.html index.htm; &#125;&#125; 配置强制跳转到https12345678910111213141516171819202122232425262728293031323334353637383940server&#123; listen 80; server_name www.m.com; return 301 https://$server_name/$request_uri;&#125;server&#123; listen 443 ssl http2; server_name www.m.com; ssl on; ssl_certificate cert/www.m.com.crt; ssl_certificate_key cert/www.m.com.key; #内部跳转 307 #add_header Strict-Transport-Security "max-age=63072000; includeSubdomains; preload"; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers "ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4:!3DES:!DHE"; ssl_prefer_server_ciphers on; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; expires 1h; root /data/volume/DMP/frontend/dist; error_page 404 400 /404.html; &#125; #location ~* .(js|jpg|jpeg)$ &#123; # root /data/volume/DMP/frontend/dist; # error_page 404 400 /404.html; # expires 3h; #&#125; location = /404.html &#123; root html; &#125;&#125; _注意_ ： 请求的url匹配 listen端口和server_name，如果能匹配端口但是没有server_name与之对应的，会匹配第一个listen端口，忽视server_name，如 上面的配置，直接访问http://ip会跳转到https://www.m.com_注意_：chrome浏览器在开发者模式选中disable cache情况下，301跳转仍然继续会用 cache from disk，需手动清除缓存 ctrl + shift +delete，chrome的缓存可通过chrome://net-internals/查看。 内部跳转到https在网站全站HTTPS后，如果用户手动敲入网站的HTTP地址，或者从其它地方点击了网站的HTTP链接，通常依赖于服务器端的301/302重定向跳转才能使用HTTPS服务。而第一次的HTTP请求就有可能被劫持，导致请求无法到达服务器，从而构成HTTPS降级劫持。这个问题目前可以通过HSTS(HTTP Strict Transport Security，RFC6797)来解决。add_header Strict-Transport-Security &quot;max-age=63072000; includeSubdomains; preload&quot;; 3、缓存 nginx设置浏览器缓存 nginx设置代理缓存 4、httpsopenssl安装1234567891011121314151617#下载opensslcurl -O https://www.openssl.org/source/openssl-1.0.2n.tar.gz#解压#指定安装目录./config --prefix=/usr/local/openssl./config -tmakemake install#将/usr/local/openssl/bin添加到环境变量# vim /etc/profileexport OPENSSL_HOME=/usr/local/opensslexport PATH=$PATH:$OPENSSL_HOME/bin# source /etc/profile# openssl version openssl实现私有CA参考 https://www.cnblogs.com/AloneSword/p/4656492.html TLS1.3TLS1.3是一种新的加密协议，我们把使互联网实现安全通信的基础性技术称为传输层安全协议（TLS）。TLS是安全套接层协议（SSL）的进化版本，SSL是由Netscape公司在1990年代研发的。参考 https://www.jianshu.com/p/365cb6057387]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nodejs]]></title>
    <url>%2F2018%2F01%2F18%2Fnodejs%2F</url>
    <content type="text"><![CDATA[一、JavaScript1、作用域 作用域 LHS RHS RHS查询与简单地查找某个变量的值别无二致，而LHS查询则是试图找到变量的容器本身，从而可以对其赋值。从这个角度说，RHS并不是真正意义上的“赋值操作的右侧”，更准确地说是“非左侧”。RHS理解成retrieve his source value（取到它的源值），这意味着“得到某某的值”。 非严格模式下，当引擎执行LHS查询时，如果在顶层（全局作用域）中也无法找到目标变量，全局作用域中就会创建一个具有该名称的变量，并将其返还给引擎。严格模式下则会抛出异常未声明ReferenceError，另外还有typeError 提升： 引擎会在解释JavaScript代码之前首先对其进行编译。编译阶段中的一部分工作就是找到所有的声明，并用合适的作用域将它们关联起来。当你看到var a = 2;时，可能会认为这是一个声明。但JavaScript实际上会将其看成两个声明：var a;和a = 2;。第一个定义声明是在编译阶段进行的。第二个赋值声明会被留在原地等待执行阶段。只有声明本身会被提升，而赋值或其他运行逻辑会留在原地。函数声明的提升高于变量声明。 匿名函数 (function(args){})(args) var 和 let，let关键字可以将变量绑定到所在的任意作用域中（通常是{ .. }内部）。换句话说，let为其声明的变量隐式地劫持了所在的块作用域。let只能运行在严格模式下。 1234567891011121314151617181920212223var foo = true;if (foo) &#123; let bar = foo * 2; bar = something( bar ); console.log( bar );&#125;console.log( bar ); // 因为let ， 对于用let声明的bar，if()&#123;&#125;变成一个块作用域，所以在外部引用bar 时， 未声明，不存在变量 ReferenceErrorvar foo = true;if (foo) &#123; var a = 2; const b = 3; // 包含在if中的块作用域常量 a = 3; // 正常! b = 4; // 错误!&#125;console.log( a ); // 3console.log( b ); // ReferenceError! //const同样会劫持块作用域，b在外部引用就是未声明，var声明的a则不存在劫持块作用域，const定义变量值不可改变 2、闭包 把内部函数baz传递给bar，当调用这个内部函数时（现在叫作fn），它涵盖的foo()内部作用域的闭包就可以观察到了，因为它能够访问a。 1234567891011121314151617181920212223242526272829303132333435363738394041function foo() &#123; var a = 2; function baz() &#123; console.log( a ); // 2 &#125; bar( baz );&#125;function bar(fn) &#123; fn(); // 妈妈快看呀，这就是闭包！&#125;//间接传递函数var fn;function foo() &#123; var a = 2; function baz() &#123; console.log( a ); &#125; fn = baz; // 将baz分配给全局变量&#125;function bar() &#123; fn(); // 妈妈快看呀，这就是闭包！&#125;foo();bar(); // 2// jquery examplefunction setupBot(name, selector) &#123; $( selector ).click( function activator() &#123; console.log( "Activating:" + name ); &#125; );&#125;setupBot( "Closure Bot 1", "#bot_1" );setupBot( "Closure Bot 2", "#bot_2" ); 虽然以下段代码可以正常工作，但严格来讲它并不是闭包。为什么？因为函数（示例代码中的IIFE）并不是在它本身的词法作用域以外执行的。它在定义时所在的作用域中执行（而外部作用域，也就是全局作用域也持有a）。a是通过普通的词法作用域查找而非闭包被发现的。 12345var a = 2;(function IIFE() &#123; console.log( a );&#125;)(); 循环中的闭包 1234567891011121314151617181920212223242526272829303132333435for (var i=1; i&lt;=5; i++) &#123; setTimeout( function timer() &#123; console.log( i ); &#125;, i*1000 );&#125;//运行时会以每秒一次的频率输出五次6// for循环每次迭代并没有创建一个新的作用域 for (var i=1; i&lt;=5; i++) &#123; (function() &#123; setTimeout( function timer() &#123; console.log( i ); &#125;, i*1000 ); &#125;)();&#125;// 不行，虽然每次迭代立即执行函数创建新的作用域，但是一个空作用域，不包含ifor (var i=1; i&lt;=5; i++) &#123; (function(j) &#123; // 或则 var j = i; setTimeout( function timer() &#123; console.log( j ); &#125;, j*1000 ); &#125;)( i );&#125;// 每秒一次，输出1~5 ， 每次迭代，变量i当前值赋予函数的参数 j 并被封装到函数作用域中。// let劫持块作用域，这样for每次迭代对let声明的i 都是一个新的块作用域for (let i=1; i&lt;=5; i++) &#123; setTimeout( function timer() &#123; console.log( i ); &#125;, i*1000 );&#125; 模块，如下代码：CoolModule()只是一个函数，必须要通过调用它来创建一个模块实例。如果不执行外部函数，内部作用域和闭包都无法被创建。CoolModule()返回一个用对象字面量语法{ key: value, … }来表示的对象。这个返回的对象中含有对内部函数而不是内部数据变量的引用。我们保持内部数据变量是隐藏且私有的状态。可以将这个对象类型的返回值看作本质上是模块的公共API。这个对象类型的返回值最终被赋值给外部的变量foo，然后就可以通过它来访问API中的属性方法，比如foo.doSomething()。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788function CoolModule() &#123; var something = &quot;cool&quot;; var another = [1, 2, 3]; function doSomething() &#123; console.log( something ); &#125; function doAnother() &#123; console.log( another.join( &quot; ! &quot; ) ); &#125; return &#123; doSomething: doSomething, doAnother: doAnother &#125;;&#125;var foo = CoolModule(); foo.doSomething(); // coolfoo.doAnother(); // 1 ! 2 ! 3 //我们将模块函数转换成了IIFE（参见第3章），立即调用这个函数并将返回值直接赋值给单例的模块实例标识符foo。var foo = (function CoolModule() &#123; var something = &quot;cool&quot;; var another = [1, 2, 3]; function doSomething() &#123; console.log( something ); &#125; function doAnother() &#123; console.log( another.join( &quot; ! &quot; ) ); &#125; return &#123; doSomething: doSomething, doAnother: doAnother &#125;;&#125;)();foo.doSomething(); // cool foo.doAnother(); // 1 ! 2 ! 3//模块也是普通的函数，因此可以接受参数function CoolModule(id) &#123; function identify() &#123; console.log( id ); &#125; return &#123; identify: identify &#125;;&#125;var foo1 = CoolModule( &quot;foo 1&quot; ); var foo2 = CoolModule( &quot;foo 2&quot; );foo1.identify(); // &quot;foo 1&quot;foo2.identify(); // &quot;foo 2&quot;//模块模式另一个简单但强大的用法是命名将要作为公共API返回的对象var foo = (function CoolModule(id) &#123; function change() &#123; // 修改公共API publicAPI.identify = identify2; &#125; function identify1() &#123; console.log( id ); &#125; function identify2() &#123; console.log( id.toUpperCase() ); &#125; var publicAPI = &#123; change: change, identify: identify1 &#125;; return publicAPI;&#125;)( &quot;foo module&quot; );foo.identify(); // foo modulefoo.change();foo.identify(); // FOO MODULE 现代的模块机制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152var MyModules = (function Manager() &#123; var modules = &#123;&#125;; function define(name, deps, impl) &#123; for (var i=0; i&lt;deps.length; i++) &#123; deps[i] = modules[deps[i]]; &#125; modules[name] = impl.apply( impl, deps ); // apply函数 继承，deps作为参数传入，此处为函数依赖的其他函数 &#125; function get(name) &#123; return modules[name]; &#125; return &#123; define: define, get: get &#125;;&#125;)();//这段代码的核心是modules[name] = impl.apply(impl, deps)。//为了模块的定义引入了包装函数（可以传入任何依赖），并且将返回值，也就是模块的API，储存在一个根据名字来管理的模块列表中 MyModules.define( &quot;bar&quot;, [], function() &#123; function hello(who) &#123; return &quot;Let me introduce: &quot; + who; &#125; return &#123; hello: hello &#125;;&#125; );MyModules.define( &quot;foo&quot;, [&quot;bar&quot;], function(bar) &#123; var hungry = &quot;hippo&quot;; function awesome() &#123; console.log( bar.hello( hungry ).toUpperCase() ); &#125; return &#123; awesome: awesome &#125;;&#125; );var bar = MyModules.get( &quot;bar&quot; );var foo = MyModules.get( &quot;foo&quot; );console.log( bar.hello( &quot;hippo&quot; )); // &lt;i&gt;Let me introduce: hippo&lt;/i&gt;foo.awesome(); // LET ME INTRODUCE: HIPPO ES6模块机制 ， ES6的模块没有“行内”格式，必须被定义在独立的文件中（一个文件一个模块）。浏览器或引擎有一个默认的“模块加载器”（可以被重载，但这远超出了我们的讨论范围）可以在导入模块时同步地加载模块文件。 1234567891011121314151617//bar.js function hello(who) &#123; return &quot;Let me introduce: &quot; + who; &#125;export hello;//foo.js// 仅从&quot;bar&quot;模块导入hello()import hello from &quot;bar&quot;;var hungry = &quot;hippo&quot;;function awesome() &#123; console.log( hello( hungry ).toUpperCase() );&#125;export awesome; import可以将一个模块中的一个或多个API导入到当前作用域中，并分别绑定在一个变量上（在我们的例子里是hello）。module会将整个模块的API导入并绑定到一个变量上（在我们的例子里是foo和bar）。export会将当前模块的一个标识符（变量、函数）导出为公共API。 当函数可以记住并访问所在的词法作用域，即使函数是在当前词法作用域之外执行，这时就产生了闭包。 3、 动态作用域 事实上JavaScript并不具有动态作用域。它只有词法作用域，简单明了。但是this机制某种程度上很像动态作用域。 123456789101112131415 function foo() &#123; console.log( a ); // 2&#125;function bar() &#123; var a = 3; foo();&#125;var a = 2;bar();// foo中的a 会通过RHS查询到全局的a，基于词法作用域查找// 词法作用域最重要的特征是它的定义过程发生在代码的书写阶段// 如果基于动态作用域，作用域链是基于调用栈的，即foo向上查找bar中的a 主要区别：词法作用域是在写代码或者说定义时确定的，而动态作用域是在运行时确定的。（this也是！）词法作用域关注函数在何处声明，而动态作用域关注函数从何处调用 4、 this 对this的认识，this既不指向函数自身也不指向函数的词法作用域，抛开以前错误的假设和理解。this实际上是在函数被调用时发生的绑定，它指向什么完全取决于函数在哪里被调用。 1、 this并不像我们所想的那样指向函数本身 2、this在任何情况下都不指向函数的词法作用域。 12345678910function foo() &#123; var a = 2; this.bar();&#125;function bar() &#123; console.log( this.a );&#125;foo(); // ReferenceError: a is not defined this是在运行时进行绑定的，并不是在编写时绑定，它的上下文取决于函数调用时的各种条件。this的绑定和函数声明的位置没有任何关系，只取决于函数的调用方式。 绑定规则 1、默认绑定，当调用foo()时，this.a被解析成了全局变量a。为什么？因为在本例中，函数调用时应用了this的默认绑定，因此this指向全局对象。foo()是直接使用不带任何修饰的函数引用进行调用的，因此只能使用默认绑定，无法应用其他规则。如果使用严格模式（strict mode），则不能将全局对象用于默认绑定，因此this会绑定到undefined 12345678function foo() &#123; // &quot;use strict&quot;; 严格模式 console.log( this.a );&#125;var a = 2;foo(); // 2 2、隐式绑定，如下，调用位置会使用obj上下文来引用函数，因此你可以说函数被调用时obj对象“拥有”或者“包含”它。当foo()被调用时，它的前面确实加上了对obj的引用。当函数引用有上下文对象时，隐式绑定规则会把函数调用中的this绑定到这个上下文对象。因为调用foo()时this被绑定到obj，因此this.a和obj.a是一样的。对象属性引用链中只有上一层或者说最后一层在调用位置中起作用，如obj1.obj2.foo(); 则foo()的this指向obj2。隐式绑定时，我们必须在一个对象内部包含一个指向函数的属性，并通过这个属性间接引用函数，从而把this间接（隐式）绑定到这个对象上。 12345678910function foo() &#123; console.log( this.a );&#125;var obj = &#123; a: 2, foo: foo &#125;;obj.foo(); // 2 如下代码，虽然bar是obj.foo的一个引用，但是实际上，它引用的是foo函数本身，因此此时的bar()其实是一个不带任何修饰的函数调用，因此应用了默认绑定。 12345678910111213function foo() &#123; console.log( this.a );&#125;var obj = &#123; a: 2, foo: foo &#125;;var bar = obj.foo; // 函数别名！var a = &quot;oops, global&quot;; // a是全局对象的属性 bar(); // &quot;oops, global 参数传递其实就是一种隐式赋值，因此我们传入函数时也会被隐式赋值，fn = obj.foo 123456789101112131415161718192021222324252627282930313233343536373839function foo() &#123; console.log( this.a );&#125;function doFoo(fn) &#123; // fn其实引用的是foo fn(); // &lt;-- 调用位置！&#125;var obj = &#123; a: 2, foo: foo &#125;;var a = &quot;oops, global&quot;; // a是全局对象的属性doFoo( obj.foo ); // &quot;oops, global&quot;//js的内置函数一样，将函数传递给另一函数的形参，其中包含了隐式赋值function foo() &#123; console.log( this.a );&#125;var obj = &#123; a: 2, foo: foo &#125;;var a = &quot;oops, global&quot;; // a是全局对象的属性setTimeout( obj.foo, 100 ); // &quot;oops, global&quot;//JavaScript环境中内置的setTimeout()函数实现和下面的伪代码类似function setTimeout(fn,delay) &#123; // 等待delay毫秒 fn(); // &lt;-- 调用位置！&#125; 显示绑定，通过call()和apply()函数实现，它们的第一个参数是一个对象，是给this准备的，接着在调用函数时将其绑定到this。因为你可以直接指定this的绑定对象，因此我们称之为显式绑定。 1234567891011121314151617181920212223242526272829303132333435363738394041function foo() &#123; console.log( this.a );&#125;var obj = &#123; a:2&#125;;//显示指定foo函数中的this并执行该函数foo.call( obj ); // 2//硬绑定，是一种非常常用的模式，所以ES5提供了内置的方法Function.prototype.bind，它的用法如下function foo(something) &#123; console.log( this.a, something ); return this.a + something;&#125;var obj = &#123; a:2&#125;;var bar = foo.bind( obj );//将foo函数的this绑定到obj,返回一个新的foo函数实例barvar b = bar( 3 ); // 2 3 console.log( b ); // 5//第三方库的许多函数，以及JavaScript语言和宿主环境中许多新的内置函数，都提供了一个可选的参数，//通常被称为“上下文”（context），其作用和bind(..)一样，确保你的回调函数使用指定的this。function foo(el) &#123; console.log( el, this.id );&#125;var obj = &#123; id: &quot;awesome&quot;&#125;;// 调用foo(..)时把this绑定到obj[1, 2, 3].forEach( foo, obj );// 1 awesome 2 awesome 3 awesome//这些函数实际上就是通过call(..)或者apply(..)实现了显式绑定，这样你可以少写一些代码。 new 绑定 1234567891011121314151617function foo(a) &#123; this.a = a;&#125; var bar = new foo(2);//new foo(2)执行时 foo的this指向new新建的对象foo//若不用new直接执行foo()，其this指向全局作用域，同默认规则 console.log( bar.a ); // 2 // 使用new来调用函数，或者说发生构造函数调用时，会自动执行下面的操作//1. 创建（或者说构造）一个全新的对象。//2. 这个新对象会被执行[[Prototype]]连接。//3. 这个新对象会绑定到函数调用的this。//4. 如果函数没有返回其他对象，那么new表达式中的函数调用会自动返回这个新对象。//new foo(2)创建一个全新的foo对象，this指向的就是foo对象，返回foo 胖箭头=&gt;，箭头函数不使用this的四种标准规则，而是根据外层（函数或者全局）作用域来决定this。箭头函数的绑定无法被修改。 123456789101112function foo() &#123; setTimeout(() =&gt; &#123; // 这里的this在词法上继承自foo() console.log( this.a ); &#125;,100);&#125;var obj = &#123; a:2&#125;;foo.call( obj ); // 2 5、对象 语法，声明 1234567var myObj = &#123; key: value // ...&#125;; var myObj = new Object();myObj.key = value; 对象类型 12345678910111213141516171819// 对象是JavaScript的基础。在JavaScript中一共有六种主要类型，基本类型（术语是“语言类型”）：stringnumberbooleannullundefinedobject//基本类型按照值传递//内置对象StringNumberBooleanObjectFunctionArrayDateRegExpError 值传递，基本类型按照值传递，对象其实也是按值传递。js的基础类型原始值存储在栈中，对象存储在堆中，堆地址不能直接访问，所有栈中存储它的地址，引用值是存储栈中的指向堆的地址。参考https://www.zhihu.com/question/27114726/answer/35481766 12345678910111213141516171819202122232425var obj = &#123;x : 1&#125;;function foo(o) &#123; o = 100;&#125;foo(obj);console.log(obj.x); // 仍然是1, obj并未被修改为100.//var obj1 = &#123; value:&apos;111&apos;&#125;;var obj2 = &#123; value:&apos;222&apos;&#125;;function changeStuff(obj)&#123; obj.value = &apos;333&apos;; obj = obj2; return obj.value;&#125; var foo = changeStuff(obj1); console.log(foo);// &apos;222&apos; 参数obj指向了新的对象obj2console.log(obj1.value);//&apos;333&apos; ES6增加了可计算属性名，可以将对象的key用变量表示，即对变量加上[] 12345678910var prefix = &quot;foo&quot;;var a=&quot;bar&quot;var myObject = &#123; [a]: &quot;hello&quot;, [&quot;baz&quot;]: &quot;world&quot; &#125;;console.log(myObject[&quot;bar&quot;]); // helloconsole.log(myObject[&quot;baz&quot;]); // world ES6定义了Object.assign(..)方法来实现浅复制，方法的第一个参数是目标对象，之后还可以跟一个或多个源对象。 123456var newObj = Object.assign( &#123;&#125;, myObject );newObj.a; // 2newObj.b === anotherObject; // truenewObj.c === anotherArray; // truenewObj.d === anotherFunction; // true 6、类二、Node.js InterviewJS基础问题1、内存释放 引用类型是在没有引用之后, 通过 v8 的 GC 自动回收, 值类型如果是处于闭包的情况下, 要等闭包没有引用才会被 GC 回收, 非闭包的情况下等待 v8 的新生代 (new space) 切换的时候回收. 内存泄漏几种情况 全局变量 1234567891011121314151617a = 10;//未声明对象。global.b = 11;//全局变量引用//全局变量直接挂在 root 对象上，不会被清除掉。////非严格模式下bar会被定义到全局变量，页面中的全局变量只有在页面关闭后才会被销毁function foo(arg) &#123; bar = &quot;some text&quot;;&#125;////function foo() &#123; this.var1 = &quot;potential accidental global&quot;;&#125;// Foo 被调用时, this 指向全局变量(window)，意外的创建了全局变量.foo(); 闭包，闭包会引用到父级函数中的变量，如果闭包未释放，就会导致内存泄漏。如下代码是 inner 直接挂在了 root 上，从而导致内存泄漏（bigData 不会释放）。 123456function out() &#123; const bigData = new Buffer(100); inner = function () &#123; void bigData; &#125;&#125; 未销毁的定时器和全局函数，如下代码：如果后续 renderer 元素被移除, 整个定时器实际上没有任何作用. 但如果你没有回收定时器, 整个定时器依然有效, 不但定时器无法被内存回收, 定时器函数中的依赖也无法回收. 在这个案例中的 serverData 也无法被回收. 1234567var serverData = loadData();setInterval(function() &#123; var renderer = document.getElementById(&apos;renderer&apos;); if(renderer) &#123; renderer.innerHTML = JSON.stringify(serverData); &#125;&#125;, 5000); // 每 5 秒调用一次 事件监听 Js中的内存管理，参考https://zhuanlan.zhihu.com/p/30552148 2、ES6]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓝鲸运维平台部署]]></title>
    <url>%2F2017%2F11%2F20%2Fblueking%2F</url>
    <content type="text"><![CDATA[蓝鲸智云，简称蓝鲸，是腾讯游戏运营部“腾讯智营”下的子品牌。它是一套基于 PaaS 的技术解决方案，提供了完善的前后台开发框架、调度引擎、公共组件等模块，帮助业务的产品和技术人员快速构建低成本、免运维的支撑工具和运营系统；是腾讯游戏运营部沉淀多年的技术运营支撑体系，承担着数百款业务线上运营的使命。 准备 时间12345678vim /etc/profileTZ=&apos;Asia/Shanghai&apos;; export TZsource /etc/profileyum install -y ntpdatentpdate ntp.d.com 1、三台服务器之间 配置域名 1234567891011192.168.110.4192.168.110.5192.168.110.6# vim /etc/hosts 192.168.110.4 blue1 192.168.110.5 blue2 192.168.110.6 blue3 192.168.110.4 paas.blue.d.com cmdb.blue.d.com jobs.blue.d.com 2、服务器之间免密登录 3、安装文件上传到blue1的/data/目录下 1234567891011121314151617tar xf bkce_src-3.1.7.tgztar xf install_ce-1.0.15.tgzvim /data/install/install.config192.168.110.4 nginx,appt,rabbitmq,kafka,zk,es,bkdata,consul,fta192.168.110.5 license,appo,kafka,zk,es,mysql,beanstalk,consul192.168.110.6 paas,cmdb,job,gse,kafka,zk,es,consul,redis,bkarchiva# 查看三台服务器Mac地址，http://bk.tencent.com/download/#ssl 下载证书ip link show # 将证书解压到 /data/src/cert/目录下cd /data/src/certtar xf /data/ssl_certificates.tar.gz#修改默认配置 域名 密码vim /data/install/globals.env 4、更换yum源，pip源 1234567891011 # http://mirrors.163.com/.help/centos.html mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo yum clean all yum makecache #修改pip源vim /data/src/.pip/pip.confindex-url = http://mirrors.aliyun.com/pypi/simpletrusted-host = mirrors.aliyun.com 5、添加源 12345 # nginxrpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm# 在192.168.110.5 安装beanstalk的服务器上 添加 epelcurl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 6、yum -y groupinstall &quot;Development Tools&quot; 7、安装1234567$ ./bk_install base_service # 安装基础环境$ ./bk_install bk_products # 安装蓝鲸主要产品，并初始化数据# 该步骤安装完成后，可以通过浏览器打开蓝鲸了。cmdb，job 都应该能访问才算是正常$ ./bk_install app_mgr # 安装 开发者中心的 App 管理器# 该步骤安装完成后， 可以在开发者中心的 服务器信息 和 第三方服务信息 中看到已经成功激活的服务器$ ./bk_install gse_agent # 在所有机器上安装 gse_agent# 该步骤安装完成后，可以在 CC 的资源池中看到安装蓝鲸的服务器 ip 列表 维护方案更新域名1、修改 globals.env 中的域名配置信息，/etc/hosts中的配置信息2、顺序执行以下命令:1234567891011121314151617181920212223242526$ ./bkcec stop paas$ ./bkcec stop bkdata$ ./bkcec stop fta$ ./bkcec stop job$ ./bkcec stop cmdb$ ./bkcec stop nginx$ ./bkcec render nginx 1$ ./bkcec render paas 1$ ./bkcec render job 1$ ./bkcec render cmdb 1$ ./bkcec render fta 1$ ./bkcec render bkdata 1$ ./bkcec start nginx$ ./bkcec start paas$ ./bkcec start job$ ./bkcec start cmdb$ ./bkcec start bkdata$ ./bkcec start fta## 若web应用面板中agent的ip没有变 ## 需要在安装appo的 服务器下查看 /data/bkce/paas_agent/paas_agent/etc/paas_agent_config.yaml## 修改CONTROLLER_SERVER_URL，重启appo 重新部署agent## 安装agent时，如果报错 /tmp/iagent/install_agent.sh: line 1: syntax error near unexpected token `newline'## 查看http://10.0.12.70:80/download/app/install_agent.sh 无法访问## 编辑中控机的/data/bkce/etc/nginx/miniweb.conf 在server_name后添加 10.0.12.70 agent安装配置 http://bbs.bk.tencent.com/forum.php?mod=viewthread&amp;tid=165&amp;page=1#pid578 agent的错误排查方法 http://bbs.bk.tencent.com/forum.php?mod=viewthread&amp;tid=463&amp;highlight=agent 常见问题http://bbs.bk.tencent.com/forum.php?mod=viewthread&amp;tid=570&amp;extra=page%3D1]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL备份]]></title>
    <url>%2F2017%2F11%2F18%2Fmysql%2F</url>
    <content type="text"><![CDATA[MySQL安装 添加 MySQL Yum Repository 1sudo yum -y localinstall http://mirrors.d.com/software/mysql/5.7/mysql57-community-release-el7-11.noarch.rpm 默认是最新版5.7版本的mysql，需要安装5.6版本，所以修改/etc/yum.repos.d/mysql-community.repo文件，修改对应版本的enabled字段，如下 12345[mysql57-community]enabled=0[mysql57-community]enabled=1 安装sudo yum -y install mysql-community-server，启动sudo service mysqld start，验证安装是否成功mysqladmin --version 设置默认root的用户密码 mysqladmin -u root password &quot;123456&quot;;，登录mysql -u root -p 添加用户及权限GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP ON TUTORIALS.* TO &#39;username&#39;@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;，其中%表示所有客户端ip可连接，可指定IP可连接。也可以直接操作mysql数据库下的user表管理用户。 Mysql备份 开启binlog日志 1234vim /etc/my.cnflog_bin=mysql-bin binlog_format=row 常用操作 123456mysql&gt; show master logs; #查看数据库所有日志文件。mysql&gt; flush logs; #将内存中log日志写磁盘，保存在当前binlog文件中，并产生一个新的binlog日志文件。mysql&gt; reset master; #删除所有二进制日志，在（mysql-bin.000001）开始记录。 mysqldump --all-databases &gt; dump.sqlmysqldump --databases db1 db2 db3 &gt; dump.sql xtrabackup备份 1、安装 12345yum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpmyum install percona-xtrabackup-24yum -y install perl-DBD-MySQL.x86_64 2、创建备份用户 12345mysql&gt; grant reload,lock tables,replication client on *.* to &apos;backup&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;mysql&gt; grant process on *.* to backup@&apos;localhost&apos;;mysql&gt; flush privileges; 3、全量物理备份 生成当前时间戳命名的备份文件 1innobackupex --user=backup --password=123456 /data/mysql/backup 让备份文件准备，备份文件不能直接用于恢复，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务，此时数据文件处于不一致的状态。因此，我们现在就是要通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。 1innobackupex --user=backup --password=123456 --apply-log /data/mysql/backup/2017-11-24_14-11-17 将mysql的数据目录链接到这个已经恢复的备份目录，或直接用copy-back拷贝至mysql数据目录 1234567systemctl stop mysqldmv mysql mysql.oldln -s /data/mysql/backup/2017-11-24_14-11-17/ /var/lib/mysqlchown mysql:mysql /var/lib/mysqlchown -R mysql:mysql /data/mysql/backup/*systemctl start mysqld #重启mysql即可 恢复 4、增量备份 12345678910111213141516#全备innobackupex --user=backup --password=123456 /data/mysql/backup #第一次增量备份innobackupex --user=backup --password=123456 --incremental /data/mysql/backup/inc --incremental-basedir=/data/mysql/backup/2017-11-24_14-11-17/#第二次增量备份innobackupex --user=backup --password=123456 --incremental /data/mysql/backup/inc --incremental-basedir=incremental /data/mysql/backup/inc/2017-11-24_14-18-35#恢复 innobackupex --apply-log --redo-only ~/data/mysql/backup/full/2017-11-24_16-29-09/## 注意每次恢复后设置 备份文件的mysql用户权限innobackupex --apply-log --redo-only /data/mysql/backup/full/2017-01-20_10-52-43 --incremental-dir=/data/mysql/backup/inc/2017-01-20_11-04-31 shell 脚本 mysql和xtrabackup安装 123456789101112131415161718192021222324252627282930313233343536##### mysql 安装 默认5.7 yum -y install http://mirrors.d.com/software/mysql/5.7/mysql57-community-release-el7-11.noarch.rpm #echo "#### install mysql：默认安装最新版5.7， 若需要之前版本需要修改/etc/yum.repos.d/mysql-community.repo 中对应版本的enabled值"yum -y install mysql-community-servermysqladmin --version# deta目录 /var/lib/mysqlif [ ! -d /var/lib/mysql ]; then echo install mysql failed exit 0;fiservice mysqld start###### mysql 设置#设置 root 密码 123456mysqladmin -u root password "123456";#允许所有客户端访问 ##mysql -uroot -p123456 -D mysql -e "update user set Host='%' where User='root' and Host='127.0.0.1';"# Grant all on *.* to 'root'@'%' identified by 'password' with grant option;mysql -uroot -p123456 -e "Grant all on *.* to 'root'@'%' identified by 'password' with grant option;"#创建备份用户 backup 123456mysql -uroot -p123456 -e "grant reload,lock tables,replication client ,process on *.* to 'backup'@'localhost' identified by '123456';"mysql -uroot -p123456 -e ' flush privileges;'mysql -uroot -p123456 -D mysql -e 'select host,user from user;' #xtrabackup安装 yum -y install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpmyum -y install percona-xtrabackup-24#yum -y install perl-DBD-MySQL.x86_64 备份脚本，定时执行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/bin/bash# mysql备份文件，该文件每天执行，每周一全备，每天基于本周一的全备做增量备份#全备最近四周，增备最近七天# crontab -e# 00 03 * * 1 /data/mysql/backup/backup.shbackupfull_dir='/data/mysql/backup/full'backupinc_dir='/data/mysql/backup/inc'username='backup'password='123456'#需要在备份服务器上对备份文件定期删除处理backup_host='10.0.12.59' last4week_day=`date -d -4weeks '+%Y-%m-%d'` week_day=`date +%w`lastmon_day=`date -d "last Mon" +"%Y-%m-%d"`today=`date +%Y-%m-%d`# Every Monday full back if [ $week_day == 1 ]; then #周一删除四周前的基础备份，新增基础备份 rm -rf $&#123;backupfull_dir&#125;/$&#123;last4week_day&#125;* ulimit -n 65535 &amp;&amp; innobackupex --user=$username --password=$password $backupfull_dir #备份文件传到其他服务器 if [ $backup_host ]; then new_full=`ls $&#123;backupfull_dir&#125; |grep $today` #tar czvf $&#123;new_full&#125;.tar $new_full cd $backupfull_dir &amp;&amp; tar -cf - $&#123;new_full&#125; | pigz &gt; $&#123;new_full&#125;.tgz rsync -rl $&#123;new_full&#125;.tar root@10.0.12.59:/data/mysql/backup/full rm -rf $&#123;new_full&#125;.tar fifi#每天增量备份，基于周一的全备full_dir=`ls $&#123;backupfull_dir&#125; |grep $lastmon_day`if [ $full_dir ]; then ulimit -n 65535 &amp;&amp; innobackupex --user=$username --password=$password --incremental $backupinc_dir --incremental-basedir=$&#123;backupfull_dir&#125;/$&#123;full_dir&#125; #备份文件传到其他服务器 if [ $backup_host ]; then new_inc=`ls $&#123;backupinc_dir&#125; |grep $today` #tar czvf $&#123;new_inc&#125;.tar $new_inc cd $backupinc_dir &amp;&amp; tar -cf - $&#123;new_inc&#125; | pigz &gt; $&#123;new_inc&#125;.tgz rsync -rl $&#123;new_inc&#125;.tar root@10.0.12.59:/data/mysql/backup/inc rm -rf $&#123;new_inc&#125;.tar fifi#删除 一周之前的增量备份find $backupinc_dir -maxdepth 1 -mtime +7 | xargs rm -rf mariadb安装 yum源 123456789101112#vim /etc/yum.repo.d/MariaDB.repo# MariaDB 10.1 CentOS repository list - created 2016-12-01 03:36 UTC# http://downloads.mariadb.org/mariadb/repositories/[mariadb]name = MariaDBbaseurl = http://yum.mariadb.org/10.1/centos7-amd64gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDBgpgcheck=1 #yum clean all #yum makecache 安装sudo yum -y install MariaDB-server MariaDB-client 使用mysql_secure_installation配置MariaDB服务 1234567891011121314151617181920212223#由于一开始安装MariaDB数据库后, root用户默认密码为空, 所以只需要按Enter键Enter current password for root (enter for none):#是否设置root用户的新密码Set root password? [Y/n] y#录入新密码New password:#确认新密码Re-enter new password:#是否删除匿名用户,生产环境建议删除Remove anonymous users? [Y/n] y#是否禁止root远程登录,根据自己的需求选择Disallow root login remotely? [Y/n] n#是否删除test数据库Remove test database and access to it? [Y/n] y#是否重新加载权限表Reload privilege tables now? [Y/n] y 用户配置，远程访问设置同mysql MariaDB的日志在 /etc/logs/messages 12345678910[mysqld]datadir=/data/mysql_test #修改默认路径socket=/data/mysql_test/mysql.sock#default-character-set=utf8character_set_server=utf8slow_query_log=onslow_query_log_file=/data/mysql_test/slow_query_log.log#long_query_time=2mysql_install_db --user=mysql --basedir=/usr --datadir=/data/mysql_test/]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PM2设置开机自启动]]></title>
    <url>%2F2017%2F07%2F17%2Fpm2%2F</url>
    <content type="text"><![CDATA[运行 pm2 startup，即在/etc/init.d/目录下生成pm2-root的启动脚本，且自动将pm2-root设为服务。 运行 pm2 save，会将当前pm2所运行的应用保存在/root/.pm2/dump.pm2下，当开机重启时，运行pm2-root服务脚本，并且到/root/.pm2/dump.pm2下读取应用并启动。 参考 http://doocr.com/articles/5894d4b53c6bfb7e3b7fe20f]]></content>
      <categories>
        <category>运维</category>
      </categories>
  </entry>
</search>
